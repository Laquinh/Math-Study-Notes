\section{Block Codes}

\subsection{Exercise 1}

\begin{formulationBox}
	Consider the code of words of the form $(m_1, m_2, m_3, m_4, r_1, r_2, r_3, r_4)$, where $(m_1, m_2, m_3, m_4)$ is the binary message we want to transmit and the redundant bits $(r_1, r_2, r_3, r_4)$ are defined by the following conditions. The sum of the number of ones in rows and columns 1 to 2 should be even.
	
	\begin{center}
		\begin{tabular}{|c|c|c|}
			\hline
			$m_1$ & $m_2$ & $r_1$\\
			\hline
			$m_3$ & $m_4$ & $r_2$\\
			\hline
			$r_3$ & $r_4$ \\
			\cline{1-2}
		\end{tabular}
	\end{center}
	
	Show that this code corrects one error.
\end{formulationBox}

If an error occurs in one of the of the message's bits, then the parity check in that row and that column will fail, so the error is located at those coordinates, and by flipping the bit the error is corrected.

If an error occurs in $r_3$ or $r_4$, then the parity check in its column will fail, but row parity checks will be correct, hence by elimination the error is located at the redundant bit's row, and by flipping the bit the error is corrected.

The reasoning for $r_1$ and $r_2$ is virtually the same.

$\qed$

\subsection{Exercise 2}

\begin{formulationBox}
	Let $C$ be the code of all $n \times n$ binary arrays that have an even number of ones in every row and column. What is the number of codewords of $C$? What is the minimum distance of $C$? Show that every pattern of three erasures can be corrected.
\end{formulationBox}

Let's first prove there exists exactly one codeword for every $(n-1)\times(n-1)$ binary array.

Take any binary array
\[A = \begin{pmatrix}
	a_{1,1} & a_{1,2} & \cdots & a_{1,n-1} \\
	a_{2,1} & a_{2,2} & \cdots & a_{2,n-1} \\
	\cdots & \cdots & \ddots & \vdots \\
	a_{n-1,1} & a_{n-1,2} & \cdots & a_{n-1,n-1} \\
\end{pmatrix}.\]
Then, we can build up an array
\[A' = \begin{pmatrix}
	a_{1,1} & a_{1,2} & \cdots & a_{1,n-1} & a_{1,n} \\
	a_{2,1} & a_{2,2} & \cdots & a_{2,n-1} & a_{2,n}\\
	\cdots & \cdots & \ddots & \vdots & \vdots \\
	a_{n-1,1} & a_{n-1,2} & \cdots & a_{n-1,n-1} & a_{n-1,n} \\
	a_{n,1} & a_{n,2} & \cdots & a_{n,n-1} & a_{n,n} \\
\end{pmatrix}\]
such that $A' \in C$, by setting the elements in the $n^\textrm{th}$ row and column to be equal to 1 when the number of ones in rest of elements is odd, and 0 otherwise. Likewise, if a bit in the $n^\textrm{th}$ row or column were flipped, then a bit in another row or column would need to be flipped as well, in order for the parity to be preserved.

This shows that the number of codewords of $C$ is exactly the number of possible $(n-1)\times(n-1)$ binary arrays; that is, $2^{(n-1)(n-1)}$.

The minimum distance of $C$ is equal to $2$; you can flip two elements in the same row or column preserving the parity, but that's not possible with a single flip.

Finally, an erasure can be corrected if the remaining elements in its row or its column have all be received. Let an erasure be at row $i$ and column $j$. Then, the worst case scenario would be having one other erasure in row $i$ and one other in column $j$, which would at first not let us correct the erasure at $i, j$. But we could then take one of the other erasures, say the one at $i, j'$ without loss of generality, and column $j'$ must have all the rest of elements set. This allows the erasure at $i, j'$ to be corrected first, and we would then be able to correct the erasure at $i, j$ and $i', j$.

\subsection{Exercise 3}

\begin{formulationBox}
	Let $Q = \{1,2,\hdots,n\}$. Let $C$ be the code in $Q^n$ of all $(c_1, c_2, \hdots, c_n)$ such that $\{c_1, c_2, \hdots, c_n\} = Q$. What is the number of codewords of $C$? What is the minimum distance of $C$? Show that for every received word with one error there are exactly two nearest codewords.
\end{formulationBox}

The number of codewords of $C$ is the number of permutations of $n$ letters; that is, $n!$.

The minimum distance of $C$ is $2$. Note that all letters in the alphabet appear in each codeword exactly once. Let $c \in C$. If one of $c$'s letters were to be changed from $c_a$ to $c_b$, then the position that used to hold the value $c_b$ also needs to change in order for $c_b$ not to be repeated.

Finally, if a word $w$ contains one error, that means there is exactly one letter in the alphabet (say $l$) that appears twice in the word (say at positions $i$ and $j$), and exactly one letter in the alphabet (say $l'$) that doesn't appear in the word at all. Then, the nearest codewords would be the one having $l$ at position $i$ and $l'$ at position $j$, and the one having $l'$ at position $i$ and $l$ at position $j$.

\subsection{Exercise 4}

Check UPV/EHU Coding Theory notes.

\subsection{Exercise 5}

\begin{formulationBox}
	Let $d_i$ be a metric on the set $\mathcal{X}_i$. Define for $(x_1, y_1), (x_2, y_2) \in \mathcal{X}_1\times\mathcal{X}_2$: $d((x_1, x_2), (y_1, y_2)) = d_1(x_1, y_1) + d_2(x_2, y_2)$. Show that $d$ is a metric on $\mathcal{X}_1\times\mathcal{X}_2$.
\end{formulationBox}

I believe this exercise's formulation contains an errata, since $y_1$ is first treated as an element of $\mathcal{X}_2$, but later as an element of $\mathcal{X}_1$ as well. I believe this is the correct formulation:

\textit{Define for $(x_1, x_2), (y_1, y_2) \in \mathcal{X}_1\times\mathcal{X}_2$: $d((x_1, x_2), (y_1, y_2)) = d_1(x_1, y_1) + d_2(x_2, y_2)$.}

Let's now prove that the properties of a metric are valid for $d$:

\begin{enumerate}[label=\alph*)]
	\item $d((x_1, x_2), (y_1, y_2))\geq0$, and equality holds if and only if $(x_1, x_2) = (y_1, y_2)$: $d$ is the sum of two distances, which by definition are non-negative. $d$ will be $0$ if and only if $d_1$ and $d_2$ are $0$ too, which by definition is equivalent to $x_1 = y_1$ and $x_2 = y_2$; that is, $(x_1, x_2) = (y_1, y_2)$.
	
	\item $d((x_1, x_2), (y_1, y_2)) = d((y_1, y_2), (x_1, x_2))$ (symmetry):
	\begin{align*}
		d((x_1, x_2), (y_1, y_2)) &= d_1(x_1, y_1) + d_2(x_2, y_2) \\
		&= d_1(y_1, x_1) + d_2(y_2, x_2) \\
		&= d((y_1, y_2), (x_1, x_2)).
	\end{align*}

	\item $d((x_1, x_2), (z_1, z_2)) \leq d((x_1, x_2), (y_1, y_2)) + d((y_1, y_2), (z_1, z_2))$ (triangle inequality):
	\begin{align*}
		d((x_1, x_2), (z_1, z_2)) &= d_1(x_1, z_1) + d_2(x_2, z_2) \\
		&\leq d_1(x_1, y_1) + d_1(y_1, z_1) + d_2(x_2, y_2) + d_2(y_2, z_2) \\
		&= d_1(x_1, y_1) + d_2(x_2, y_2) + d_1(y_1, z_1) + d_2(y_2, z_2) \\
		&= d((x_1, x_2), (y_1, y_2)) + d((y_1, y_2), (z_1, z_2)).
	\end{align*}
\end{enumerate}

$\qed$

\subsection{Exercise 6}

\begin{formulationBox}
	Let $Q = \{0, 1, \hdots, q-1\}$. Let $d(\textbf{x}, \textbf{y}) = \sum_{i=1}^n \min\{|x_i-y_i|, q - |x_i - y_i|\}$ for $\textbf{x}, \textbf{y} \in Q^n$. Show that $d$ is a metric on $Q^n$. It is called the \textit{Lee metric}.
\end{formulationBox}

\begin{enumerate}[label=\alph*)]
	\item $d(\textbf{x}, \textbf{y})\geq0$, and equality holds if and only if $\textbf{x} = \textbf{y}$:
	
	Note that $x_i$ and $y_i$ can at most have value $q-1$, so $|x_i - y_i|$ is restricted to the interval $[0, q-1]$. The expression in the summation will therefore always have a non-negative value, and so will the Lee distance.
	
	If $\textbf{x} = \textbf{y}$, then $|x_i - y_i| = 0$, so all the addends will be equal to $0$, and so will $d(\textbf{x}, \textbf{y})$.
	
	Likewise, if $d(\textbf{x}, \textbf{y}) = 0$, that means the addends are all equal to $0$ (since they are all non-negative), and because $q - |x_i - y_i|$ is restricted to the interval $[1, q]$, that means $|x_i - y_i|$ must be equal to $0$. This only happens when $x_i = y_i$, which, in turn, means $\textbf{x} = \textbf{y}$.
	
	\item $d(\textbf{x}, \textbf{y}) = d(\textbf{y}, \textbf{x})$ (symmetry):
	
	This is a trivial result given that $|x_i - y_i| = |-(y_i - x_i)| = |y_i - x_i|$.
	
	\item $d(\textbf{x}, \textbf{z}) \leq d(\textbf{x}, \textbf{y}) + d(\textbf{y}, \textbf{z})$ (triangle inequality):
	
	%\begin{align*}
	%	d(\textbf{x}, \textbf{z}) &= \sum_{i=1}^n \min\{|x_i-z_i|, q - |x_i - z_i|\} \\
	%	&= \sum_{i=1}^n \min\{|x_i-y_i+y_i-z_i|, q - |x_i - y_i + y_i - z_i|\} \\
	%	&\leq \sum_{i=1}^n \min\{|x_i-y_i|+|y_i-z_i|, q - |x_i - y_i + y_i - z_i|\} \\
	%	&? \sum_{i=1}^n \min\{|x_i - y_i|, q - |x_i - y_i|\} + \min\{|y_i-z_i|, q - |y_i - z_i|\}\\
	%	&= \sum_{i=1}^n \min\{|x_i - y_i|, q - |x_i - y_i|\} + \sum_{i=1}^n \min\{|y_i-z_i|, q - |y_i - z_i|\} \\
	%	&= d(\textbf{x}, \textbf{y}) + d(\textbf{y}, \textbf{z})
	%\end{align*}
	
	\begin{itemize}
		\item If $d_l(x, z) = |x - z|$:
		\begin{itemize}
			\item If $d_l(x, y) = |x - y|$ and $d_l(y, z) = |y - z|$: Then $|x - z| \leq |x - y| + |y - z|$ by the absolute value's triangle inequality.
			\item If $d_l(x, y) = q - |x - y|$ and $d_l(y, z) = q - |y - z|$: Then
			I have no idea :skull:
			
		\end{itemize}
	\end{itemize}
\end{enumerate}
